{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch concordances and analyze them\n",
    "\n",
    "Lars G. Johnsen, National Library of Norway\n",
    "\n",
    "lars.johnsen@nb.no\n",
    "\n",
    "Solstrand june 2021\n",
    "\n",
    "\n",
    "In this code we will fetch arbitrary concordances, and use them in conjunction with a parser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "#import spacy\n",
    "from dhlab.module_update import css\n",
    "\n",
    "def search_nb(word = 'demokrati', window=20, limit = 300):\n",
    "    parameters = {\n",
    "        'query': word,\n",
    "        'window':window,\n",
    "        'limit':limit\n",
    "    }\n",
    "    r = requests.get(\"https://api.nb.no/ngram/db1/konk\", params = parameters)\n",
    "    return pd.DataFrame(json.loads(r.text), columns = 'doc-id concordance'.split())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code `spacy.load` below may not work, in that case uncomment the cell below and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download nb_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"nb_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(string):\n",
    "    cols = \"token.text, token.lemma_, token.pos_, token.tag_, token.dep_, token.shape_, token.is_alpha, token.is_stop\".split(', ')\n",
    "    doc = nlp(string)\n",
    "    rows = [(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,\n",
    "            token.shape_, token.is_alpha, token.is_stop) for token in doc]\n",
    "    return pd.DataFrame(rows, columns = cols), doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', None)\n",
    "css()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concordances\n",
    "\n",
    "A random collection of newspapers, periodicals and/or books are created on each query. Use SQLite fts5 syntax in formulating search https://www2.sqlite.org/fts5.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df = search_nb(\"\"\" sjarken \"\"\", limit = 300)\n",
    "df.style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy and paste cells to run new versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search_nb(\"\"\" NEAR(spiser middag, 5) \"\"\", limit = 20).style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search_nb(\"NEAR(fiske* snøre*)\", limit = 200).style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse the concordances using Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of `parse`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse('Han liker at hun studerer lingvistikk.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse('... Han lik att hun studerer lingvistikk.')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect all the concordances \n",
    "\n",
    "These are all contained in the variable `df`\n",
    "\n",
    "The function parse returns the parse as a data frame or as a spacy doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the phrase markers and parse the sentences\n",
    "\n",
    "parses = [parse(s.replace(\"<b>\", \"\").replace(\"</b>\",\"\")) for s in df['concordance']]\n",
    "\n",
    "df_versions = [p[0] for p in parses]\n",
    "spacy_docs = [p[1] for p in parses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parses = pd.concat(df_versions)\n",
    "df_parses.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check out frequency of some tags\n",
    "\n",
    "The expressions here are raw Pandas or Python. Perhaps a wrapper could be in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parses.groupby(\"token.pos_\").count()['token.text'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of wrapper for the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parse(relation):\n",
    "    if relation != 'token.text':\n",
    "        res = df_parses.groupby(relation).count()['token.text'].sort_values(ascending=False)\n",
    "    else:\n",
    "        res = df_parses.groupby(relation).count()['token.dep_'].sort_values(ascending=False)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The wrapper makes it easier to write the command for inspecting the parsing result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_parse('token.dep_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which words are in certain relations?\n",
    "\n",
    "Searching using standard pandas expressions. Back to involved expressions!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parses[df_parses['token.dep_'] == 'nsubj'].groupby('token.text').count()['token.lemma_'].sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Se på et tre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.concordance[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.displacy.render(spacy_docs[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "\n",
    "Run the code again, and check if the frequencies change. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
